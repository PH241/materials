---
title: "Lab 6"
subtitle: "Public Health 241: Statistical Analysis of Categorical Data"
author: "YOUR NAME / YOUR STUDENT ID HERE"
date: "TODAY'S DATE"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)
library(dplyr)
library(foreign)
library(epitools)
library(epiR)
library(ORCI)
library(knitr)
library(vcd)
```

In this lab, we’ll cover tools you’ll need to complete Homework 7 (concepts covered up to and including Chapter 9), and recap/add to the general-use functions we’ve learned in previous labs. Functions introduced in this lab will allow us to consider the concepts of interaction and confounding as they affect our analysis of the main effects of a principal exposure variable.

## 1. Stratified Analyses

Today, we'll again be using the Western Collaborative Group Study data.

### 1.1: Load the WCGS dataset into R.

``` {r one}
wcgs <- read.dta("data/wcgs.dta")
```

### 1.2: Familiarize yourself with the variables in your dataset. A Word document containing a description of the study and all the variables in the dataset is available on bCourses.

We have loaded our dataset into a variable called `wcgs`, which is saved as a dataframe. Let's take a look at one of the variables in the dataset: `Ncigs`, which is the number of cigarettes smoked in the study. We'll explore using a few important statistical functions to find the distribution of the variable, as well as finding any missing values in the data.

``` {r two.one}
summary(wcgs)
```

We now have a non-parametric summary of the data we have acquired. While most things are unimportant to us now, we want to make sure that we catch any instances of `NAs`. If this shows up anywhere in the summary, we have found `NaNs` in our dataset. Missing values are particularly important when generating new variables from pre-existing variables, since (as pointed out in past labs), a missing value will be treated as $+\infty$ in an inequality. This is not the behavior desired, and so it is a good idea in that situation to check for missing values in your variables.

There are two variables with missing values in `wcgs`: `chol0` and `arcus0`. When doing kind of analysis or experiments, it is generally good practice to address these missing values. This can be dropping rows with missing values (`wcgs[-c(ROW IDX TO DROP)]`) or imputation (replacing with mean of the variable), which are the two most popular methods.

### 1.3: Look at the distribution of the `weight0` variable in particular.

``` {r three}
w <- wcgs$weight0
summary(w)
hist(w, prob=TRUE, xlim=c(min(w), max(w)))
```

The distribution for this variable looks roughly normal. We decide that weight is a possible confounding variable in determining the probability of a person having coronary heart disease (`chd69 == 1`) or not (`chd69 == 0`). To determine a range that would be statistically significant, we will turn the `weight0` column into a categorical variable.

### 1.4 Weight is a suspected confounder in the relationship between two variables of interest, Behavior Pattern and Coronary Heart Disease. Generate a categorical variable for weight and divide the continuous weight variable into the following categories:

* $< 150$ lbs
* $\geq 150$ lbs and $< 160$ lbs
* $\geq 160$ lbs and $< 170$ lbs
* $\geq 170$ lbs and $< 180$ lbs
* $\geq 180$ lbs

The best solution to do this is to use base R's function `cut()` and label these into a new column in our dataframe. An example is shown below.

``` {r four}
wcgs$weight.cats<-cut(wcgs$weight0, c(0, 150, 160, 170, 180, max(wcgs$weight0) + 1) , right=FALSE, labels=c(1:5))
summary(wcgs)
```

* We passed in the relevant column `wcgs$weight0`
* Specified a vector of values for the limit points `c(0, 150, 160, 170, 180, max(wcgs$weight0) + 1)`. The +1 is there because we need to include the max value, and because we are looking at the left inclusive ranges (`right=FALSE`). 
* Finally, labels specify the value associated to that range `labels=c(1:5)`

### 1.5 Examine the odds ratio for coronary heart disease associated with behavior pattern. Take a look at the relative risk.

``` {r five}
chd.dibpat <- sum(wcgs$chd69 & wcgs$dibpat0)
chd.no.dibpat <- sum(wcgs$chd69 & !wcgs$dibpat0)
no.chd.dibpat <- sum(!wcgs$chd69 & wcgs$dibpat0)
no.chd.no.dibpat <- sum(!wcgs$chd69 & !wcgs$dibpat0)

matr <- matrix(c(chd.dibpat, no.chd.dibpat, chd.no.dibpat, no.chd.no.dibpat), ncol=2)
tabl <- as.table(matr)
epi.2by2(tabl)
```

This is an exercise we've now done many times! What we're more interested in seeing is whether this number for relative risk changes for different weight categories.


### 1.6: We can now examine the odds ratio and relative risk for coronary heart disease and behavior pattern for each of the weight categories defined above using the by option, for Relative Risk:

``` {r six.one}
for (i in 1:5) {
  temp <- wcgs[wcgs$weight.cats == i,]
  chd.dibpat <- sum(temp$chd69 & temp$dibpat0)
  chd.no.dibpat <- sum(temp$chd69 & !temp$dibpat0)
  no.chd.dibpat <- sum(!temp$chd69 & temp$dibpat0)
  no.chd.no.dibpat <- sum(!temp$chd69 & !temp$dibpat0)
  
  matr <- matrix(c(chd.dibpat, no.chd.dibpat, chd.no.dibpat, no.chd.no.dibpat), ncol=2)
  tabl <- as.table(matr)
  print(epi.2by2(tabl))
}
```

By adding one more option to the `epi.2by2()` function, we can tell R to use the Woolf method for calculating weights, rather than the default Mantel-Haenszel method:

``` {r six.two}
chd.dibpat <- sum(wcgs$chd69 & wcgs$dibpat0)
chd.no.dibpat <- sum(wcgs$chd69 & !wcgs$dibpat0)
no.chd.dibpat <- sum(!wcgs$chd69 & wcgs$dibpat0)
no.chd.no.dibpat <- sum(!wcgs$chd69 & !wcgs$dibpat0)

matr <- matrix(c(chd.dibpat, no.chd.dibpat, chd.no.dibpat, no.chd.no.dibpat), ncol=2)
tabl <- as.table(matr)
epi.2by2(tabl, homogeneity ="woolf") # Woolf!
```

7. What do these estimates tell you qualitatively about interaction and confounding? How can you use the Mantel-Haenszel to sum up your opinions about confounding? Make sure that you can interpret the results of this test. Compare the CMH test statistic with the overall $\chi^2$ test statistic from the unstratified analysis.

One Last Note:

* Since this lab focuses on odds ratios, which can be calculated using the same equations for cohort, population-based, and case-control studies, you may use either `cohort.count` or `case.control`, regardless of your study design. The output should be identical.

\newpage

## 2. Optional

If you’d like to explore stratification further, here are some additional questions you could explore in the Titanic dataset, `titanicdata.dta`.

Using the Titanic data from bCourses, generate a new variable died, that will take on a value of 1 if the individual didn’t survive the trip, and 0 otherwise. Examine the possible confounding effects of age (a simple adult/child dummy variable) on the association between `sex` and `died` (for passengers only). What is the relative risk of death for adults? How about children? Use the Cochran-Mantel-Haenszel test for independence, to determine the evidence for death being independent of sex, controlling for the simple age variable. What kind of causal graph do you imagine in this case? Now look at the age as an exposure, and sex as a possible confounder. Is sex a confounder? What form of causal graph underlies your reasoning in this case?
